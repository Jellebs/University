{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import * \n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1.5, 1.2, 5.8, 6.2, 6.5]).reshape(-1, 1)\n",
    "mu_0 = [2, 3]\n",
    "sd_0 = [0.1,0.1] \n",
    "pi_0 = [0.5,0.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N1=[np.float64(3.0), np.float64(3.0)]\n",
      "gamma1=[array([[1.00000000e+000],\n",
      "       [1.00000000e+000],\n",
      "       [1.00000000e+000],\n",
      "       [4.81749166e-144],\n",
      "       [0.00000000e+000],\n",
      "       [0.00000000e+000]]), array([[7.17509597e-66],\n",
      "       [3.72007598e-44],\n",
      "       [3.48110684e-57],\n",
      "       [1.00000000e+00],\n",
      "       [1.00000000e+00],\n",
      "       [1.00000000e+00]])]\n",
      "mu1=[array([[1.23333333]]), array([[6.16666667]])]\n",
      "sd1=[np.float64(220.16), np.float64(220.16)]\n",
      "pi1=[np.float64(0.5), np.float64(0.5)]\n"
     ]
    }
   ],
   "source": [
    "gamma = lambda x, k, mus, sds, pis : pis[k] * norm.pdf(x, loc = mus[k], scale = sds[k])/(pis[0] * norm.pdf(x, loc = mus[0], scale = sds[0]) + pis[1] * norm.pdf(x, loc = mus[1], scale = sds[1]))\n",
    "muk = lambda Nk, gammak, x : (1/Nk) * np.dot(gammak.T, x) \n",
    "sdk = lambda Nk, gammak, x, muk : np.sum([gammak * (xn - muk) * (xn - muk) for xn in x])\n",
    "pik = lambda Nk, N : Nk/N\n",
    "N1 = [np.sum(gamma(x, 0, mu_0, sd_0, pi_0)), np.sum(gamma(x, 0, mu_0, sd_0, pi_0))] \n",
    "gamma1 = [gamma(x, 0, mu_0, sd_0, pi_0), gamma(x, 1, mu_0, sd_0, pi_0)]\n",
    "mu1 = [muk(N1[0],gamma1[0], x), muk(N1[1],gamma1[1], x)]\n",
    "sd1 = [sdk(N1[0], gamma1[0], x, mu1[0]), sdk(N1[0], gamma1[0], x, mu1[0])]\n",
    "pi1 = [pik(N1[0], len(x)), pik(N1[1], len(x))]\n",
    "\n",
    "print(f\"{N1=}\\n{gamma1=}\\n{mu1=}\\n{sd1=}\\n{pi1=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code I've previously used for expectation maximization of multivariate normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture(x, means, covariances, pis):\n",
    "    pdfx = np.sum([pis[k] * multivariate_normal.pdf(x = x, mean = means[k], cov = covariances[k]) for k in range(len(means))], axis=0)\n",
    "    return pdfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_maximization_gaussian(mus_0, covariances_0, pis_0, data_x, on_step):\n",
    "    # Evaluation\n",
    "    # So the evaluation acts as an average of the k'th object with xn over all the K objects. \n",
    "    # The denorminator is exactly what I just did in previous function. \n",
    "    # The length K do I determine from the length of means.\n",
    "    # The length of N do I determine from the length of datapoints x. \n",
    "    \n",
    "    N, D = data_x.shape # Datapoints and dimension of x\n",
    "    K = len(mus_0)\n",
    "    gamma = np.zeros((N, K))\n",
    "    for n in range(N): \n",
    "        denominator = gaussian_mixture(data_x[n], mus_0, covariances_0, pis_0)\n",
    "        xn = data_x[n]\n",
    "        \n",
    "        # Gamma(znk)\n",
    "        for k in range(K): \n",
    "            gamma[n, k] = (pis_0[k]/denominator) * multivariate_normal.pdf(x = xn, mean=mus_0[k], cov=covariances_0[k])\n",
    "        \n",
    "            \n",
    "    # Now for reestimating     \n",
    "    mean_new = np.zeros(mus_0.shape)\n",
    "    cov_new = np.zeros(covariances_0.shape)\n",
    "    pis_new = np.zeros(pis_0.shape)\n",
    "    \n",
    "    # Functions: \n",
    "    meank = lambda Nk, gamma, x : (1/Nk) * np.sum(gamma[:, k].reshape(-1, 1) * x[:], axis = 0)\n",
    "    covk = lambda Nk, gamma, xn, mean_new : (1/Nk) * gamma[n, k] * np.outer(xn - mean_new,(xn - mean_new).T)       \n",
    "    for k in range(K): \n",
    "        Nk = np.sum(gamma[:, k]) # Nk = np.sum(n=1 -> N (gammaznk in R^150x3))    => sum = [sum_k1, sum_k2, sum_k3] = np.sum(gamma[:, k]), iterating over every k\n",
    "        mean_new[k] = meank(Nk, gamma, data_x)\n",
    "        for n in range(N): \n",
    "            cov_new[k] += covk(Nk, gamma, data_x[n], mean_new[k])     \n",
    "        pis_new[k] = Nk/N\n",
    "      \n",
    "        \n",
    "    # Evaluation: \n",
    "    # The logLikeliHood is just the sum over the natural logarithm to the gaussian mixture. It's the exact same as the denominator in gamma. \n",
    "    logLikeliHood = lambda pis, x, mean, cov : np.sum([\n",
    "        np.log(\n",
    "            np.sum([pis[k] * multivariate_normal.pdf(x[n], mean[k], cov[k]) \n",
    "                    for k in range(K)])) \n",
    "        for n in range(N)])\n",
    "    \n",
    "    # I haven't been given a exact criteria on when to stop, so make me do it when |logLikeliHoodk - logLikeliHoodk-1| < 0.00001\n",
    "    criteria = 0.00001\n",
    "    logLikeliHoodk_1 = logLikeliHood(pis =   pis_0, x = data_x, mean =    mus_0, cov = covariances_0)\n",
    "    logLikeliHoodk =   logLikeliHood(pis = pis_new, x = data_x, mean = mean_new, cov =       cov_new)\n",
    "    \n",
    "    # Appending data before checking criteria. \n",
    "    predictions = np.argmax(gamma, axis=1) # gamma in R^150x3, for every n which of the columns is highest? The column index == k therefore this gives me k. \n",
    "    on_step(mean_new, cov_new, pis_new, logLikeliHoodk, predictions)\n",
    "    \n",
    "    if np.abs(logLikeliHoodk - logLikeliHoodk_1) < criteria: \n",
    "        return\n",
    "    else : \n",
    "        expectation_maximization_gaussian(mus_0=mean_new, covariances_0=cov_new, pis_0=pis_new, data_x=data_x, on_step=on_step)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to solve for the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "When `allow_singular is False`, the input matrix must be symmetric positive definite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m covariances_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mcov(x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mT)] \u001b[38;5;241m*\u001b[39m classes)\n\u001b[1;32m     14\u001b[0m pis_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mclasses] \u001b[38;5;241m*\u001b[39m classes)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mexpectation_maximization_gaussian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmus_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariances_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpis_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_steps_em\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_steps_em))\n\u001b[1;32m     21\u001b[0m  \u001b[38;5;66;03m#print(all_steps_em[0])\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(\"\\n\\n\\n\\n\\n\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#print(all_steps_em[17])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[89], line 56\u001b[0m, in \u001b[0;36mexpectation_maximization_gaussian\u001b[0;34m(mus_0, covariances_0, pis_0, data_x, on_step)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[0;32m---> 56\u001b[0m     \u001b[43mexpectation_maximization_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmus_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariances_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpis_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpis_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 56\u001b[0m, in \u001b[0;36mexpectation_maximization_gaussian\u001b[0;34m(mus_0, covariances_0, pis_0, data_x, on_step)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[0;32m---> 56\u001b[0m     \u001b[43mexpectation_maximization_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmus_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariances_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpis_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpis_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 56\u001b[0m, in \u001b[0;36mexpectation_maximization_gaussian\u001b[0;34m(mus_0, covariances_0, pis_0, data_x, on_step)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[0;32m---> 56\u001b[0m     \u001b[43mexpectation_maximization_gaussian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmus_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovariances_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpis_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpis_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 47\u001b[0m, in \u001b[0;36mexpectation_maximization_gaussian\u001b[0;34m(mus_0, covariances_0, pis_0, data_x, on_step)\u001b[0m\n\u001b[1;32m     45\u001b[0m criteria \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00001\u001b[39m\n\u001b[1;32m     46\u001b[0m logLikeliHoodk_1 \u001b[38;5;241m=\u001b[39m logLikeliHood(pis \u001b[38;5;241m=\u001b[39m   pis_0, x \u001b[38;5;241m=\u001b[39m data_x, mean \u001b[38;5;241m=\u001b[39m    mus_0, cov \u001b[38;5;241m=\u001b[39m covariances_0)\n\u001b[0;32m---> 47\u001b[0m logLikeliHoodk \u001b[38;5;241m=\u001b[39m   \u001b[43mlogLikeliHood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpis_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m       \u001b[49m\u001b[43mcov_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Appending data before checking criteria. \u001b[39;00m\n\u001b[1;32m     50\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(gamma, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# gamma in R^150x3, for every n which of the columns is highest? The column index == k therefore this gives me k. \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[89], line 40\u001b[0m, in \u001b[0;36mexpectation_maximization_gaussian.<locals>.<lambda>\u001b[0;34m(pis, x, mean, cov)\u001b[0m\n\u001b[1;32m     33\u001b[0m     pis_new[k] \u001b[38;5;241m=\u001b[39m Nk\u001b[38;5;241m/\u001b[39mN\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluation: \u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# The logLikeliHood is just the sum over the natural logarithm to the gaussian mixture. It's the exact same as the denominator in gamma. \u001b[39;00m\n\u001b[1;32m     38\u001b[0m logLikeliHood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m pis, x, mean, cov : np\u001b[38;5;241m.\u001b[39msum([\n\u001b[1;32m     39\u001b[0m     np\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m---> 40\u001b[0m         np\u001b[38;5;241m.\u001b[39msum([pis[k] \u001b[38;5;241m*\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     41\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K)])) \n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N)])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# I haven't been given a exact criteria on when to stop, so make me do it when |logLikeliHoodk - logLikeliHoodk-1| < 0.00001\u001b[39;00m\n\u001b[1;32m     45\u001b[0m criteria \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00001\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_multivariate.py:584\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.pdf\u001b[0;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Multivariate normal probability density function.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m \n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     dim, mean, cov_object \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    586\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_quantiles(x, dim)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_multivariate.py:421\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[0;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[1;32m    414\u001b[0m dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_psd(\u001b[38;5;28;01mNone\u001b[39;00m, mean, cov)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m psd \u001b[38;5;241m=\u001b[39m \u001b[43m_PSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m cov_object \u001b[38;5;241m=\u001b[39m _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD(psd)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dim, mean, cov_object\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_multivariate.py:174\u001b[0m, in \u001b[0;36m_PSD.__init__\u001b[0;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_singular:\n\u001b[1;32m    172\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `allow_singular is False`, the input matrix must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymmetric positive definite.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError(msg)\n\u001b[1;32m    175\u001b[0m s_pinv \u001b[38;5;241m=\u001b[39m _pinv_1d(s, eps)\n\u001b[1;32m    176\u001b[0m U \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(u, np\u001b[38;5;241m.\u001b[39msqrt(s_pinv))\n",
      "\u001b[0;31mLinAlgError\u001b[0m: When `allow_singular is False`, the input matrix must be symmetric positive definite."
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "classes = 3\n",
    "\n",
    "all_steps_em = []\n",
    "x = np.array([[[2,3],\n",
    "               [4,3],\n",
    "               [4,5]], \n",
    "              [[6,6],\n",
    "               [7,5],\n",
    "               [7,7]]])\n",
    "mus_0 = x[0]\n",
    "covariances_0 = np.array([np.cov(x[0].T)] * classes)\n",
    "pis_0 = np.array([1/classes] * classes)\n",
    "\n",
    "expectation_maximization_gaussian(\n",
    "    mus_0, covariances_0, pis_0, x[0],\n",
    "    lambda mus, covs, pis, log_likelihood, predictions: all_steps_em.append((mus, covs, pis, log_likelihood, predictions))\n",
    ")\n",
    "print(len(all_steps_em))\n",
    " #print(all_steps_em[0])\n",
    "# print(\"\\n\\n\\n\\n\\n\")\n",
    "#print(all_steps_em[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.array([[ 0.6,  0.2, -0.1,  0.4],\n",
    "               [ 0.7, -1.0,  0.3,  0.2],\n",
    "               [-0.5, -0.3, -0.4, -0.8]])\n",
    "w2 = np.array([0.7, 0.7, 0.6, -0.3, -0.7]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given x1, what's y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z=array([ 0.72,  0.13, -0.03,  0.5 ])\n",
      "y=np.float64(0.941)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1, 0.1, -0.1]).reshape(-1, 1)\n",
    "z = np.dot(x1.T, w1)[0]\n",
    "pprint(f\"{z=}\")\n",
    "z1 = np.hstack([1, z]).reshape(-1, 1)\n",
    "y = np.dot(z1.T, w2)[0][0]\n",
    "print(f\"{y=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
